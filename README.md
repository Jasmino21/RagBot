# ğŸ§  Modular RAG PDF Chatbot with FastAPI, ChromaDB & Streamlit

This project is a modular **Retrieval-Augmented Generation (RAG)** application that allows users to upload PDF documents and chat with an AI assistant that answers queries based on the document content. It features a microservice architecture with a decoupled **FastAPI backend** and **Streamlit frontend**, using **ChromaDB** as the vector store and **Groq's LLaMA3 model** as the LLM.

---

## ğŸ“‚ Project Structure

```
ragbot2.0/
â”œâ”€â”€ client/         # Streamlit Frontend
â”‚   |â”€â”€components/
|   |  |â”€â”€chatUI.py
|   |  |â”€â”€history_download.py
|   |  |â”€â”€upload.py
|   |â”€â”€utils/
|   |  |â”€â”€api.py
|   |â”€â”€app.py
|   |â”€â”€config.py
â”œâ”€â”€ server/         # FastAPI Backend
â”‚   â”œâ”€â”€ chroma_store/ ....after run
|   |â”€â”€modules/
â”‚      â”œâ”€â”€ load_vectorestore.py
â”‚      â”œâ”€â”€ llm.py
â”‚      â”œâ”€â”€ pdf_handler.py
â”‚      â”œâ”€â”€ query_handlers.py
|   |â”€â”€uploaded_pdfs/ ....after run
â”‚   â”œâ”€â”€ logger.py
â”‚   â””â”€â”€ main.py
â””â”€â”€ README.md
```

---

## âœ¨ Features

- ğŸ“„ Upload and parse PDFs
- ğŸ§  Embed document chunks with HuggingFace embeddings
- ğŸ’‚ï¸ Store embeddings in ChromaDB
- ğŸ’¬ Query documents using LLaMA3 via Groq
- ğŸŒ Microservice architecture (Streamlit client + FastAPI server)


## ğŸŒŸ Credits

- [LangChain](https://www.langchain.com/)
- [ChromaDB](https://www.trychroma.com/)
- [Groq](https://groq.com/)
- [Streamlit](https://streamlit.io/)


